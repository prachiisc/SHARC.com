<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos."> -->
  <!-- <meta name="keywords" content="Nerfies, D-NeRF, NeRF"> -->
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Overlap-aware End-to-End Supervised Hierarchical Graph Clustering for Speaker Diarization </title>

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <!-- <link rel="stylesheet" href="./static/css/bulma-carousel.min.css"> -->
  <!-- <link rel="stylesheet" href="./static/css/bulma-slider.min.css"> -->
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <!-- <script src="./static/js/bulma-carousel.min.js"></script> -->
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
  <style>
    div.relative {
      border: 3px solid #000000;
    }
    </style>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Overlap-aware End-to-End Supervised Hierarchical Graph Clustering for Speaker Diarization</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="">Prachi Singh</a></span>
            <span class="author-block">
              <a href="">Sriram Ganapathy</a></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>2</sup> Indian Institute of Science, Bangalore</span>
          </div>
          <br>
          <!-- <h3 style="font-size:25px;font-weight:bold">Submitted to ICASSP 2023</h3> -->

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <svg class="svg-inline--fa fa-file-pdf fa-w-12" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="file-pdf" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512" data-fa-i2svg=""><path fill="currentColor" d="M181.9 256.1c-5-16-4.9-46.9-2-46.9 8.4 0 7.6 36.9 2 46.9zm-1.7 47.2c-7.7 20.2-17.3 43.3-28.4 62.7 18.3-7 39-17.2 62.9-21.9-12.7-9.6-24.9-23.4-34.5-40.8zM86.1 428.1c0 .8 13.2-5.4 34.9-40.2-6.7 6.3-29.1 24.5-34.9 40.2zM248 160h136v328c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V24C0 10.7 10.7 0 24 0h200v136c0 13.2 10.8 24 24 24zm-8 171.8c-20-12.2-33.3-29-42.7-53.8 4.5-18.5 11.6-46.6 6.2-64.2-4.7-29.4-42.4-26.5-47.8-6.8-5 18.3-.4 44.1 8.1 77-11.6 27.6-28.7 64.6-40.8 85.8-.1 0-.1.1-.2.1-27.1 13.9-73.6 44.5-54.5 68 5.6 6.9 16 10 21.5 10 17.9 0 35.7-18 61.1-61.8 25.8-8.5 54.1-19.1 79-23.2 21.7 11.8 47.1 19.5 64 19.5 29.2 0 31.2-32 19.7-43.4-13.9-13.6-54.3-9.7-73.6-7.2zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-74.1 255.3c4.1-2.7-2.5-11.9-42.8-9 37.1 15.8 42.8 9 42.8 9z"></path></svg><!-- <i class="fas fa-file-pdf"></i> Font Awesome fontawesome.com -->
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark" disabled="">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="hero-body">
    <div class="columns is-centered">
      <div class="column is-8">
        <!-- <video poster="" id="teaser" autoplay="" muted="" loop="" height="100%">
          <source src="./data/videos/teaser_new_1.mp4" type="video/mp4">
        </video> -->
      <!-- </br> -->
    <!-- </br> -->
        <h2 class="subtitle has-text-centered">
          Our method performs Speaker Diarization using a supervised hierarchical clustering approach called SHARC, which trains a graph neural network with speaker embeddings as the nodes and similarity scores as the edges.
        </h2>
        <h2 class="subtitle is-3">
          Our contributions:
        <h2>
          (a) Provide a comprehensive mathematical and algorithmic description of graph-based clustering for speaker diarization task.          
          (b) Develop an end-to-end diarization system using supervised graph neural network-based clustering (E-SHARC).
          (c) Introduce an overlap speaker detection approach called as E-SHARC-Overlap to assign multiple speakers for the same audio region.
          (d) Evaluate the performance on three benchmark datasets to illustrate improvements over state-of-the-art diarization systems.
        </h2>
      </div>
    </div>
  </div>
</section> 



<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
   
    
    <div class="columns is-centered">
      <div class="column is-full-width has-text-centered">
       
        <h2 class="title is-3">Abstract</h2>

        <!-- Abstract. -->
        <div class="content has-text-justified">
          <p>
            Speaker diarization, the task of segmenting an audio recording based on speaker identity, 
            constitutes an important speech pre-processing step for several downstream applications. 
            The conventional approach to diarization involves multiple steps of embedding extraction and 
            clustering, which are often op- timized in an isolated fashion. While end-to-end diarization 
            systems attempt to learn a single model for the task, they are often cumbersome to train and require 
            large supervised datasets. In this paper, we propose an end-to-end supervised hierarchical clustering 
            algorithm based on graph neural networks (GNN), called End-to-end Supervised HierARchical Clustering (E-SHARC). 
            The E-SHARC approach uses front-end mel-filterbank features as input and jointly learns an embedding extractor 
            and the GNN clustering module, performing representation learning, metric learning, 
            and clustering with end-to-end optimization. Further, with additional inputs from an external overlap detector, 
            the E-SHARC approach is capable of predicting the speakers in the overlapping speech regions. 
            The experimental evaluation on several benchmark datasets like AMI, VoxConverse and DISPLACE, 
            illustrates that the proposed E-SHARC framework improves significantly over the state-of-art diarization systems.
            
        </p>
        </div>
        <br/>
        <!--/ Abstract. -->

        
        <!-- Overview Diagram. -->
        <h2 class="title is-3">Overview Diagram</h2>
        <div class="content has-text-justified">
          <img src="./data/Inference_esharc_overlap_v6.jpg">
          <p>
            Block schematic of the E-SHARC algorithm with overlap handling. 
            (a) shows E-SHARC inference containing ETDNN and GNN module for the first speaker assignment. 
            (b) shows E-SHARC-Overlap for the second speaker assignment approach using an external overlap detector and the GNN module.
          </p>
        </div>
        <!--/ Overview Diagram. -->
        <!-- Animation. -->
        <h3 class="title is-3">Plots</h3>
        <div class="content has-text-justified">
              <img src="./data/DERvsK_v3.jpg" height="200px">
              <p align="center"> 
                Plot comparing DER performance for k ranging from 20-100 and τ ∈ {0.0, 0.4, 0.8} for Voxconverse dev set.
              </p> 
          </div>

          <!-- <h3 class="title is-5">2D scatter plot showing no. of ground truth speakers vs no. of predicted speakers using (a) SC and (b) ESHARC on Voxconverse dev set. The different colors represent different ranges of average DER (%) for a pair of (#ground speaker, #predicted speakers).</h3> -->
          <div class="content has-text-justified">
                <img src="./data/scatter_plot.jpg" height="200px">
                <p> 
                  2D scatter plot showing no. of ground truth speakers vs no. of predicted speakers using (a) SC and (b) ESHARC on Voxconverse dev set. The different colors represent different ranges of average DER (%) for a pair of (#ground speaker, #predicted speakers).                
                </p>
               
            </div>
         <!-- Animation. -->
        

      </div>
    </div>
    <!--/ All Stages. -->

    <!--/ Animation. -->

  </div>
</section>


<section class="section">
       
</br>
    <!-- Animation. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width has-text-centered">
        <h2 class="title is-3">Other Domains</h2>

  </div> -->
</section>


<!-- <section class="hero teaser">
  <div class="hero-body">
    <div class="columns is-centered has-text-centered">
      <div class="column is-8">
        <video id="matting-video" autoplay controls muted loop height="100%">
          <source src="./data/videos/smoke.mp4"
                  type="video/mp4">
        </video>
        <p>Wildfire Smoke</p>
      </div>
    </div>
  </div>
</section> -->

<!-- <section class="section"> -->
  


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{singh2023audio,
      title={Audio Retrieval for Multimodal Design Documents: A New Dataset and Algorithms},
      author={Singh, Prachi and Karanam, Srikrishna and Shekhar, Sumit},
      journal={arXiv preprint arXiv:2302.14757},
      year={2023}
    }
</code></pre>
  </div>
</section>

<section class="section" id="acknowledgements">
  <div class="container is-max-desktop content">
        <h2 class="title">Acknowledgements</h2>
        <p>Special thanks to <a href=""> Amrit Kaul, LEAP lab(2020 - 2022), IISc </a>.</p>
        <p>Website adapted from the following <a href="http://nerfies.github.io/">template</a>.</p>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://arxiv.org/pdf/2112.03051.pdf">
        <svg class="svg-inline--fa fa-file-pdf" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="file-pdf" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512" data-fa-i2svg=""><path fill="currentColor" d="M184 208c0-4.406-3.594-8-8-8S168 203.6 168 208c0 2.062 .2969 23.31 9.141 50.25C179.1 249.6 184 226.2 184 208zM256 0v128h128L256 0zM80 422.4c0 9.656 10.47 11.97 14.38 6.375C99.27 421.9 108.8 408 120.1 388.6c-14.22 7.969-27.25 17.31-38.02 28.31C80.75 418.3 80 420.3 80 422.4zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM292 312c24.26 0 44 19.74 44 44c0 24.67-18.94 44-43.13 44c-5.994 0-11.81-.9531-17.22-2.805c-20.06-6.758-38.38-15.96-54.55-27.39c-23.88 5.109-45.46 11.52-64.31 19.1c-14.43 26.31-27.63 46.15-36.37 58.41C112.1 457.8 100.8 464 87.94 464C65.92 464 48 446.1 48 424.1c0-11.92 3.74-21.82 11.18-29.51c16.18-16.52 37.37-30.99 63.02-43.05c11.75-22.83 21.94-46.04 30.33-69.14C136.2 242.4 136 208.4 136 208c0-22.05 17.95-40 40-40c22.06 0 40 17.95 40 40c0 24.1-7.227 55.75-8.938 62.63c-1.006 3.273-2.035 6.516-3.082 9.723c7.83 14.46 17.7 27.21 29.44 38.05C263.1 313.4 284.3 312.1 287.6 312H292zM156.5 354.6c17.98-6.5 36.13-11.44 52.92-15.19c-12.42-12.06-22.17-25.12-29.8-38.16C172.3 320.6 164.4 338.5 156.5 354.6zM292.9 368C299 368 304 363 304 356.9C304 349.4 298.6 344 292 344H288c-.3438 .0313-16.83 .9687-40.95 4.75c11.27 7 24.12 13.19 38.84 18.12C288 367.6 290.5 368 292.9 368z"></path></svg><!-- <i class="fas fa-file-pdf"></i> Font Awesome fontawesome.com -->
      </a>
    </div>
  </div>
</footer>

</body>
</html>
